---
title: "DNAm_preprocess_idat"
author: "Sarah Hatzenbuheler"
date: "8 10 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Preprocessing Methylation data from idat files

# Packages
```{r}
library("TCGAbiolinks")
#library("SummarizedExperiment")
#library("IlluminaHumanMethylation450kanno.ilmn12.hg19")
library("minfi")
#library(PCAtools)
#library(ChAMP)
library(dplyr)
library(stringr)
library(wateRmelon)
library(rjson)
library(tidyr)
```
# Download from TCGA

```{r}
# set directory
setwd("~/Studium/Master/Systems Biology Maastricht/Thesis/R")

# using TCGAbiolinks package
query_idat <- GDCquery(project = "TCGA-GBM",
                        data.category = "Raw microarray data",
                        platform = "Illumina Human Methylation 450",
                        file.type = "idat",  
                        legacy = T)
# Data download
GDCdownload(query_idat, method = "client", files.per.chunk = 10)
```
# matching idat file names to patients
loading meta data
```{r}
# set wd
setwd("~/Studium/Master/Systems Biology Maastricht/Thesis/R")

# json metadata from GDC legacy portal
# https://portal.gdc.cancer.gov/legacy-archive/cart?pagination=%7B%22files%22:%7B%22from%22:20,%22size%22:20,%22sort%22:%22cases.project.project_id:asc%22%7D%7D
meta_idat <- fromJSON(file = "metadata_idat_legacy.json")
```

creating matrix of meta data with relevant information
```{r}
# create matrix with corresponding filename and TCGA barcode
idat_id <- matrix(, nrow = length(meta_idat), ncol = 2)
for (i in 1:length(meta_idat)){
  x <- meta_idat[[i]]
  idat_id[i,1] <- unlist(x$associated_entities[[1]][1]) 
  idat_id[i,2] <- x$file_name
}

#add column with filename appendiy for concatenation of new filename
idat_id <- cbind(idat_id, gsub("^.*?_","",idat_id[,2]))
idat_id[,3] <- gsub("^.*?_","",idat_id[,3])
# create column of new filename
idat_id <- as.data.frame(idat_id)
colnames(idat_id) <- c("barcode", "old_filename", "file_end")
idat_id <- idat_id %>% unite("new_filename", c(barcode,file_end), remove = FALSE)
```

File renaming
```{r}
# rename files
setwd("~/Studium/Master/Systems Biology Maastricht/Thesis/R/GDCdata/TCGA-GBM/idat")
for (i in 1:dim(idat_id)[1]){
  if (file.exists(idat_id[i, "old_filename"])) {
    file.rename(idat_id[i, "old_filename"], idat_id[i, "new_filename"])
  } else {
    cat("The file does not exist")
  }
}
```
# Reading in renamed idat files

```{r}
path <- "~/Studium/Master/Systems Biology Maastricht/Thesis/R/GDCdata/TCGA-GBM/idat"
#list.files(path)
basenames <- gsub("_Red.idat", "", idat_id$new_filename)
basenames <- gsub("_Grn.idat", "", basenames)
targets <- file.path(path, basenames)
```

```{r}
# load data into RGset
rgset <- read.metharray(unique(targets), verbose = TRUE)

# save object for faster loading
saveRDS(object = rgset, file = "RGset_idat_1.RDS", compress = FALSE)
```
load data back in, including clinical data previously established
```{r}
# idat data
#rgset <- readRDS(file = "RGset_idat_1.RDS")

# clinical data from beta value files
data.DNAm <- readRDS(file = "DNAm_data.RDS")
clinical <- data.frame(data.DNAm@colData)
rm(data.DNAm)                    
```

adjust pheno data 
```{r}
# keep only interesting columns
keep <- c("barcode", "definition", "sample_type_id", "tissue_or_organ_of_origin", "race", "gender", "ethnicity", "age_at_index", "vital_status")
pheno_temp <- clinical[, keep]
pheno_temp <- rename(pheno_temp, sample_site=tissue_or_organ_of_origin, sex = gender, 
                     age = age_at_index, tissue_definition = definition)
# reusing sample sheet information extracted from old filenames
idat_reduced <- idat_id[!duplicated(idat_id[,"barcode"]),]
sentrix_id <- str_extract(idat_reduced$old_filename, "[:digit:]{1,}(?=_?)")
sentrix_position <- str_extract(idat_reduced$old_filename, "(?<=_)[:alnum:]{1,}(?=_?)")
# combine the info
pheno <- pheno_temp[order(match(pheno_temp[,"barcode"],idat_reduced[,"barcode"])),]
pheno <- cbind(pheno, sentrix_id, sentrix_position, row.names=NULL)#targets, row.names = NULL)
#pheno <- rename(pheno, Basename = targets)
rownames(pheno) <- pheno$barcode
```

Loading in MethyLumi object --> easier to work with
```{r}
# other way to load in data: methylumi (used by Rick & for wateRmelon)
mset <- methylumIDAT(pdat = pheno, idatPath = "~/Studium/Master/Systems Biology Maastricht/Thesis/R/GDCdata/TCGA-GBM/idat")

# save data
saveRDS(object = mset, file = "MSet_idat.RDS", compress = FALSE)
```
```{r}
# load Methylumi data back in 
mset <- readRDS(file = "MSet_idat.RDS")
```

# Basic patient filtering
Filtering patients with tissue type "normal" and "recurrent tumour", as well as one patient with missing clinical data

```{r}
index <- which(pheno$sample_type_id == "01" & !is.na(pheno$sex))
#rgset <- rgset[ ,index]
mset <- mset[ ,index]
pheno <- pheno[index, ]
```


### Data Visualisation QC

# Step 1: Check distribution of methylated and unmethylated raw intensities
identifying grossly atypical (failed) samples
```{r}
# Boxplots of methylated and unmethylated probes
boxplot(log(methylated(mset)), las=2, cex.axis=0.8, 
        main = "Methylated log distribution (raw)")
boxplot(log(unmethylated(mset)), las=2, cex.axis=0.8, 
        main = "Unmethylated log distribution (raw)")
```

Looking at median intesities of methylated and unmethylated probes to check their distribution. For blood samples, median intensities under 2000 are to be filtered. However, not sure on the procedure for tissue samples.
```{r}
### extract sample intensities 
## summarise the intensities of each sample with a single value, the median 
M.median<-apply(methylated(mset), 2, median)
U.median<-apply(unmethylated(mset), 2, median)

QCmetrics<-cbind(M.median, U.median) ## create a table to store output of QC pipeline

intens.Thres<-2000 ## change this to adjust the threshold at which you filter 
pdf("~/Studium/Master/Systems Biology Maastricht/Thesis/R/QC/Scatterplot_SampleIntensity.pdf",width = 10, height = 10)
par(mfrow = c(1,2))
hist(M.median, xlab = "Median M intensity")
hist(U.median, xlab = "Median U intensity")
par(mfrow = c(1,1))
plot(M.median, U.median, pch = 16, xlab = "Median M intensity", ylab = "Median U intensity")
abline(v = intens.Thres, col = "red")
abline(h = intens.Thres, col = "red")
dev.off()
```
```{r}
# Plot for Rmd
par(mfrow = c(1,2))
hist(M.median, xlab = "Median M intensity")
hist(U.median, xlab = "Median U intensity")
```
```{r}
par(mfrow = c(1,1))
plot(M.median, U.median, pch = 16, xlab = "Median M intensity", ylab = "Median U intensity")
abline(v = intens.Thres, col = "red")
abline(h = intens.Thres, col = "red")
```

```{r}
# plot median intensity per plate to highlight technical variances
par(mfrow = c(1,2))
par(mar = c(8, 4, 1, 1))
nCol<-length(unique(pheno$sentrix_id))
boxplot(M.median ~ pheno$sentrix_id, ylab = "Median M intensity", xlab = "Plate", 
        las = 2, col = rainbow(nCol)) 
boxplot(U.median ~ pheno$sentrix_id, ylab = "Median U intensity", xlab = "Plate", 
        las = 2, col = rainbow(nCol))
```


```{r}
# Scatter plot coloured by plate
plot(M.median, U.median, pch = 16, xlab = "Median M intensity", ylab = "Median U intensity", 
     col = rainbow(nCol)[factor(pheno$sentrix_id)])
abline(v = intens.Thres, col = "red")
abline(h = intens.Thres, col = "red") 
legend("top", legend = levels(factor(pheno$sentrix_id)), col = rainbow(nCol), 
       pch = 16, ncol=7, cex = 0.5)
```
# Step 2: Checking Bisulfite conversion rate
Apparently, every assay includes fully methylted control probes, which can be used for QC. As they are fully methylated these should have DNA methylation values of ~1. The bisulfite conversion score is essentially the median of these probes, and value < 80 is taken as a failure.
Recommendation is to remove samples with <80 BS conversion.

```{r}
# bisulfite conversion using wateRmelom
bs<-bscon(mset)

# plotting and saving histogram of % of BS conversion 
pdf("~/Studium/Master/Systems Biology Maastricht/Thesis/R/QC/HistBisulphiteConversion.pdf",width = 10, height = 10)
hist(bs, xlab = "Median % BS conversion", main = "")
abline(v = 80, col = "red")
dev.off()
```
```{r}
# Saving QC metrics
QCmetrics<-cbind(QCmetrics, bs)

# Plot for Rmd
hist(bs, xlab = "Median % BS conversion", main = "")
abline(v = 80, col = "red")
```

# Check for outlier with outlyx (wateRmelon)
The outlyx function takes any beta matrix (preferably raw) and
will identify any samples that are inconsistent with the rest of the data, from
the plot we can observe that any data points that fall into the red squares
are indeed outlying and should be removed from analysis.
Outlier identification based on interquartile range (2 iq) as well as PCA (based on PC1 by default). Returns a dataframe of TRUE/FALSE per sample where TRUE is outlying.

```{r}
outlier_check <- outlyx(mset)

# looking at samples "to be removed based on previous QC plots
QCmetrics <- as.data.frame(QCmetrics)
qc_bad <- which(QCmetrics$bs < 80 | QCmetrics$M.median < 1500 | QCmetrics$U.median < 1500)
```

check raw beta distribution
```{r}
# Density plots
densityPlot(betas(mset), main="Density plot of raw beta values")

# check density plots based on potential confounders
#densityPlot(beta_mat, sampGroups = pheno$sex, main = "Density plot of raw data") # nothing
#densityPlot(beta_mat, sampGroups = pheno$sentrix_id, main = "Density plot of raw data") #nothing
densityPlot(beta_mat, sampGroups = pheno$race, main = "Density plot of raw data", legend = F)
legend("top", legend = c("black or african american", "not reported", "white"), 
       text.col = c("dark green", "red", "purple"))
densityPlot(beta_mat, sampGroups = pheno$sample_site, main = "Density plot of raw data")
```

Check AUC to compare with other data
```{r}
# calculate density matrix for each patient
beta_mat <- betas(mset)
# need to filter our NA first
probe.na <- rowSums(is.na(beta_mat))
table(probe.na == 0)
# chose those has not NA values in rows
probe <- probe.na[probe.na == 0]
beta_mat <- beta_mat[row.names(beta_mat) %in% names(probe), ]
any(is.na(beta_mat))

# check vale range, should be between 0 and 1 - it is
range(beta_mat)

library(vulcan)
# loop for densities
met_dens_raw <- vector(mode = "list", length = dim(beta_mat)[2])
names(met_dens_raw) <- colnames(beta_mat)
for (i in colnames(beta_mat)){
  met_dens_raw[[i]] =  density(beta_mat[,i])
}

# check plot
plot(NULL, xlim=c(-0.1,1.1), ylim=c(0, 5.5), ylab="density", xlab = "beta")
for(i in seq_along(met_dens_raw)) {
     lines(met_dens_raw[[i]]) }

# loop for auc
met_auc_raw <- matrix(, nrow = dim(beta_mat)[2], ncol = 1)
rownames(met_auc_raw) <- colnames(beta_mat)
for (i in colnames(beta_mat)){
  met_auc_raw[i,] =  densityauc(met_dens_raw[[i]], c(0,1))
}

# plot
plot(met_auc_raw, ylim=c(0.5,1), xlab = "patients", ylab="AUC", 
     main = "Area under density curve for raw data")
```

check MDA plots to see data distribution
Multidimesional scaling, checks the 1000 most variable positions and relates samples. Distance not to be taken absolute.
Potentially should be normalised first (scaling, compare PCA)

```{r}
# mds plot from minfi
mdsPlot(beta_mat, numPositions = 1000, sampGroups = pheno$sex, pch = 16, legendPos = "topright")
mdsPlot(beta_mat, numPositions = 1000, sampGroups = pheno$race, pch = 16, legendPos = "topright")
```

# Step 3: Check for genetically identical samples based on SNP probes

```{r}
# match order of samples with pheno info
pheno<-pheno[match(colnames(beta_mat), pheno$barcode),]

# select only SNP probes, staring with rs
betas.rs<-beta_mat[grep("rs", rownames(beta_mat)),]
# correlate beta values of SNP probes between samples
snpCor<-cor(betas.rs) # Pearson as standard (assumption of linearity, parametric)
names(snpCor)<-pheno$barcode
# set diagonal of the matrix to NA, as it would be 1 for selfcorrelation 
#(needed for maxcor, otherwise it'll always find itself)
diag(snpCor)=NA 
corMax<-apply(abs(snpCor), 1, max, na.rm = TRUE)

# Histogram of correlation frequency over all samples
hist(corMax, main = "Max. SNP correlation with all other samples", 
     xlab = "Maximum correlation (Pearson)")
```
For each sample, plot beta values per SNP probe against same value for most correlated probe.

```{r}
# Check for and identify genetically identical matches
duplicateSamples<-vector(length = ncol(snpCor))
#if(max(corMax) > 0.95){
pdf("~/Studium/Master/Systems Biology Maastricht/Thesis/R/QC/DuplicateSamples.pdf", 
    width = 15, height = 8)
par(mfrow = c(2,4))
for(i in 1:ncol(snpCor)){
    if(!TRUE%in%(snpCor[,i] == max(snpCor[,i],na.rm = T))){next} # @RRR added if no max is found for some reason
    duplicateSamples[i]<-paste(names(which(snpCor[,i] == max(snpCor[,i],na.rm = T))), 
                               sep = "|", collapse = "|")
    plot(betas.rs[,i], betas.rs[, names(which(snpCor[,i] == max(snpCor[,i],na.rm = T)))], 
         xlab = paste0(colnames(betas.rs)[i]," Cor:", 
                  round(max(snpCor[,i],na.rm = T),4)), 
         ylab = paste0(colnames(betas.rs)[which(snpCor[,i] == max(snpCor[,i],na.rm = T))])
    )
}
dev.off()

# save potential duplicates
QCmetrics<-cbind(QCmetrics, duplicateSamples)
```
```{r}
# Heatmap of correlation values
gplots::heatmap.2(abs(snpCor), trace = "none", labCol = pheno$barcode, 
                  dendrogram = "column", labRow = "", key = FALSE, scale = "none")
```





